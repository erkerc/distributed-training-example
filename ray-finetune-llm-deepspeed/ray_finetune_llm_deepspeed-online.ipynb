{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204a90fb-da94-426a-8c0c-3a0c61b01086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9337bbf2-3e16-47ba-a519-291d1c856e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6858be-dc04-48ed-bbd8-6426917d8bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440b98a3-8ed3-4072-9cc2-763d0e6c6f00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insecure request warnings have been disabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Logged into https://api.cluster-zbw6f.zbw6f.sandbox515.opentlc.com:6443'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authenticate the CodeFlare SDK\n",
    "# On OpenShift, you can retrieve the token by running `oc whoami -t`,\n",
    "# and the server with `oc cluster-info`.\n",
    "\n",
    "\n",
    "auth = TokenAuthentication(\n",
    "     token = \"sha256~MZZVbtPDET4OZRmNYx065FSFw7FjO_O0cvTASbFQAl0\",#os.getenv(\"AUTH_TOKEN\"),\n",
    "    server = \"https://api.cluster-zbw6f.zbw6f.sandbox515.opentlc.com:6443\",#os.getenv(\"API_SERVER\"),\n",
    "    skip_tls=True\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9b355e-b730-4b01-ad6e-9ba8fce8176b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml resources loaded for ray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:218: UserWarning: head_memory is being deprecated, use head_memory_requests and head_memory_limits\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:223: UserWarning: min_memory is being deprecated, use worker_memory_requests\n",
      "  warnings.warn(\"min_memory is being deprecated, use worker_memory_requests\")\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:226: UserWarning: max_memory is being deprecated, use worker_memory_limits\n",
      "  warnings.warn(\"max_memory is being deprecated, use worker_memory_limits\")\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:205: UserWarning: head_cpus is being deprecated, use head_cpu_requests and head_cpu_limits\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:210: UserWarning: min_cpus is being deprecated, use worker_cpu_requests\n",
      "  warnings.warn(\"min_cpus is being deprecated, use worker_cpu_requests\")\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:213: UserWarning: max_cpus is being deprecated, use worker_cpu_limits\n",
      "  warnings.warn(\"max_cpus is being deprecated, use worker_cpu_limits\")\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:161: UserWarning: head_gpus is being deprecated, replacing with head_extended_resource_requests['nvidia.com/gpu'] = 1\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.11/site-packages/codeflare_sdk/ray/cluster/config.py:170: UserWarning: num_gpus is being deprecated, replacing with worker_extended_resource_requests['nvidia.com/gpu'] = 1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae9abc8d564a1099a877fa9c967623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Cluster Up', icon='play', style=ButtonStyle(), tooltip='Crea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127aeaaf2d91437ba9c48cb30b04944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure the Ray cluster\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='ray',\n",
    "    namespace='llm-fine-tuning',\n",
    "    num_workers=3,\n",
    "    min_cpus=24,\n",
    "    max_cpus=24,\n",
    "    head_cpus=16,\n",
    "    min_memory=32,\n",
    "    max_memory=32,\n",
    "    head_memory=32,\n",
    "    head_gpus=1,\n",
    "    num_gpus=1,\n",
    "    image=\"quay.io/rhoai/ray:2.23.0-py39-cu121-2024.1\",\n",
    "    local_queue=\"local-queue-test\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee11013-8646-4cda-94a2-f8e731baa1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Cluster: 'ray' has successfully been created\n"
     ]
    }
   ],
   "source": [
    "# Create the Ray cluster\n",
    "cluster.up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709a09df-3871-4791-9763-5dcdc081bec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for requested resources to be set up...\n",
      "Requested cluster is up and running!\n",
      "Dashboard is ready!\n"
     ]
    }
   ],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ccda92-a0f0-4845-a13c-6aa735e75d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                   </span><span style=\"font-weight: bold; font-style: italic\"> 🚀 CodeFlare Cluster Details 🚀</span><span style=\"font-style: italic\">                   </span>\n",
       "<span style=\"font-weight: bold\">                                                                      </span>\n",
       " ╭──────────────────────────────────────────────────────────────────╮ \n",
       " │   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #008000; font-weight: bold\">Name</span>                                                           │ \n",
       " │   <span style=\"font-weight: bold; text-decoration: underline\">ray</span>                                                Active ✅   │ \n",
       " │                                                                  │ \n",
       " │   <span style=\"font-weight: bold\">URI:</span> ray://ray-head-svc.llm-fine-tuning.svc:10001              │ \n",
       " │                                                                  │ \n",
       " │   <a href=\"https://ray-dashboard-ray-llm-fine-tuning.apps.cluster-zbw6f.zbw6f.sandbox515.opentlc.com\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Dashboard🔗</span></a>                                                    │ \n",
       " │                                                                  │ \n",
       " │  <span style=\"font-style: italic\">                     Cluster Resources                     </span>     │ \n",
       " │   ╭── Workers ──╮  ╭───────── Worker specs(each) ─────────╮      │ \n",
       " │   │ <span style=\"font-weight: bold\"> # Workers </span> │  │ <span style=\"font-weight: bold\"> Memory      CPU         GPU        </span> │      │ \n",
       " │   │ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> │  │ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> │      │ \n",
       " │   │ <span style=\"color: #800080; text-decoration-color: #800080\"> 3         </span> │  │ <span style=\"color: #008080; text-decoration-color: #008080\"> 32G~32G    </span><span style=\"color: #800080; text-decoration-color: #800080\"> 24~24       1          </span> │      │ \n",
       " │   │ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> │  │ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> │      │ \n",
       " │   ╰─────────────╯  ╰──────────────────────────────────────╯      │ \n",
       " ╰──────────────────────────────────────────────────────────────────╯ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                   \u001b[0m\u001b[1;3m 🚀 CodeFlare Cluster Details 🚀\u001b[0m\u001b[3m                   \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m                                                                    \u001b[0m\u001b[1m \u001b[0m\n",
       " ╭──────────────────────────────────────────────────────────────────╮ \n",
       " │   \u001b[1;37;42mName\u001b[0m                                                           │ \n",
       " │   \u001b[1;4mray\u001b[0m                                                Active ✅   │ \n",
       " │                                                                  │ \n",
       " │   \u001b[1mURI:\u001b[0m ray://ray-head-svc.llm-fine-tuning.svc:10001              │ \n",
       " │                                                                  │ \n",
       " │   \u001b]8;id=530724;https://ray-dashboard-ray-llm-fine-tuning.apps.cluster-zbw6f.zbw6f.sandbox515.opentlc.com\u001b\\\u001b[4;34mDashboard🔗\u001b[0m\u001b]8;;\u001b\\                                                    │ \n",
       " │                                                                  │ \n",
       " │  \u001b[3m                     Cluster Resources                     \u001b[0m     │ \n",
       " │   ╭── Workers ──╮  ╭───────── Worker specs(each) ─────────╮      │ \n",
       " │   │ \u001b[1m \u001b[0m\u001b[1m# Workers\u001b[0m\u001b[1m \u001b[0m │  │ \u001b[1m \u001b[0m\u001b[1mMemory    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCPU       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mGPU       \u001b[0m\u001b[1m \u001b[0m │      │ \n",
       " │   │ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m │  │ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m │      │ \n",
       " │   │ \u001b[35m \u001b[0m\u001b[35m3        \u001b[0m\u001b[35m \u001b[0m │  │ \u001b[36m \u001b[0m\u001b[36m32G~32G   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m24~24     \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m1         \u001b[0m\u001b[35m \u001b[0m │      │ \n",
       " │   │ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m │  │ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m │      │ \n",
       " │   ╰─────────────╯  ╰──────────────────────────────────────╯      │ \n",
       " ╰──────────────────────────────────────────────────────────────────╯ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RayCluster(name='ray', status=<RayClusterStatus.READY: 'ready'>, head_cpu_requests=16, head_cpu_limits=16, head_mem_requests='32G', head_mem_limits='32G', num_workers=3, worker_mem_requests='32G', worker_mem_limits='32G', worker_cpu_requests=24, worker_cpu_limits=24, namespace='llm-fine-tuning', dashboard='https://ray-dashboard-ray-llm-fine-tuning.apps.cluster-zbw6f.zbw6f.sandbox515.opentlc.com', worker_extended_resources={'nvidia.com/gpu': 1}, head_extended_resources={'nvidia.com/gpu': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb29e733-eac5-4f3d-bbfa-543e8ee7fd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Job Submission Client\n",
    "client = cluster.job_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc30c26b-d439-4d74-b3fe-d9e84db29a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m304.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m268.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m359.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m340.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.9.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m351.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/app-root/lib64/python3.11/site-packages (from datasets) (3.10.5)\n",
      "Collecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, fsspec, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "Successfully installed datasets-3.0.2 dill-0.3.8 fsspec-2024.9.0 huggingface-hub-0.26.2 multiprocess-0.70.16 tqdm-4.66.6 xxhash-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the training and evaluation datasets.\n",
    "# This can be run only once.\n",
    "!{sys.executable} -m pip install datasets\n",
    "import create_dataset\n",
    "create_dataset.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086f3337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models-afd583f2-380a-47da-9b1a-c43070ff3e09\n"
     ]
    }
   ],
   "source": [
    "# The S3 bucket where to store checkpoint.\n",
    "# It can be set manually, otherwise it's retrieved from configured the data connection.\n",
    "s3_bucket = \"\"\n",
    "if not s3_bucket:\n",
    "    s3_bucket = os.environ.get('AWS_S3_BUCKET')\n",
    "assert s3_bucket, \"An S3 bucket must be provided to store checkpoints\"\n",
    "print(s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2be5d8-66c7-46e2-ba3b-fa2f8a03b27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 07:53:17,767\tINFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_ea6ee8edbebf577e.zip.\n",
      "2024-10-30 07:53:17,768\tINFO packaging.py:530 -- Creating a file package for local directory './'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raysubmit_C1cgciaqX6CfsRjZ\n"
     ]
    }
   ],
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=\"python ray_finetuning_llm_deepspeed-online.py \"\n",
    "               \"--model-name=meta-llama/Llama-2-7b-chat-hf \"\n",
    "               \"--lora \"\n",
    "               \"--num-devices=2 \"\n",
    "               \"--num-epochs=3 \"\n",
    "               \"--ds-config=./deepspeed_configs/zero_3_llama_2_7b.json \"\n",
    "               f\"--storage-path={s3_bucket}/ray_finetune_llm_deepspeed/ \"\n",
    "               \"--batch-size-per-device=16 \"\n",
    "               \"--eval-batch-size-per-device=32 \",\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            \"AWS_S3_ENDPOINT\": os.environ.get('AWS_S3_ENDPOINT'),\n",
    "            \"AWS_ACCESS_KEY_ID\": os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "            \"AWS_SECRET_ACCESS_KEY\": os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "            \"AWS_DEFAULT_REGION\": 'us-east-1',\n",
    "            \"AWS_S3_BUCKET\": os.environ.get('AWS_S3_BUCKET')\n",
    "        },\n",
    "        \"pip\": \"requirements.txt\",\n",
    "        \"working_dir\": \"./\",\n",
    "        \"excludes\": [\"/docs/\", \"*.ipynb\", \"*.md\", \"/tmp/\"]\n",
    "    },\n",
    ")\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8476f19b-1d51-44f5-8889-c5b01ed36343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.stop_job(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f456f161-5122-4057-a5ac-f7f6b38651ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e636e-a43b-4f29-952c-d157932b3baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
